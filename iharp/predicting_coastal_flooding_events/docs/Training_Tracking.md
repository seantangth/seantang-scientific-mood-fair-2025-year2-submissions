# iHARP Training Tracking

Status: CANONICAL training/submission run log (2026-02-18).

## Purpose
Track Colab training runs (`h100_day2_*`) with stable references after chat sessions expire.

## Active Training Entry
- Notebook: `2_notebooks/26_Colab_ModelGap_E9_v1.ipynb` (E9 multi-horizon meta route)
- Script: `3_src/train_e9_multihorizon_meta_official_v1.py`
- Packer: `3_src/create_e9_multihorizon_meta_submissions.py`
- Output root: `4_models/`

## Run Registry
| Date | Run Folder | Mode | Key Output | Notes |
|---|---|---|---|---|
| 2026-02-18 | `e9sm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/e9_fake_preds_full.csv` | Executed packaged `model.py` (`e9sm_q00010_v1`) on synthetic full-size index (`n=77799`); output valid (`null=0`, `lt05=7`, range `[0.49, 0.99]`). |
| 2026-02-18 | `e9sm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e9sm_q00010_v1.zip` | E9 packer smoke passed; generated compact ZIPs (`base/q00010`) with five-booster portable artifacts (`neg14/neg7/neg3/rel/meta`). |
| 2026-02-21 | `f4r_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/f4r_q00200_v1.zip` | Packed F4 ZIPs from `f4_14day_adaptive_v1_20260220_183849`: `base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`; NaN bug pre-fixed (packer uses `re.sub` to replace bare `NaN` with `float('nan')`). Submit `f4r_q00010_v1.zip` first gate. |
| 2026-02-21 | `f4_14day_adaptive_v1_20260220_183849` | `colab_full_run` | `4_models/f4_14day_adaptive_v1_20260220_183849/results.json` | F4 full run complete: selected=`f1_q2`, `selected_q=0.002`, `cv_auc=0.7484` (+0.026 vs F3's 0.7227, +0.104 vs E9), `neg_precision=0.9583`, `feature_dim=291`, `k_flip=456`, `tn=437`, `fn=19`, `n_windows=228281`. Best CV AUC in entire experiment series. |
| 2026-02-21 | `f3r_nan_bugfix_repack_v1` | `submission_pack_fix` | `5_outputs/submissions/f3r_q00010_v1.zip` | F3 packer NaN bug fixed: `json.dumps(float('nan'))` produced bare `NaN` token → `NameError` on Codabench; fixed via `re.sub(r"\bNaN\b", "float('nan')", ...)` in both F3 and F4 packers. Repacked all F3 ZIPs locally; `f3r_q00010_v1.zip` re-submitted to Codabench (awaiting result). |
| 2026-02-20 | `f4_route_bootstrap_v1` | `route_plan` | `0_README/Model_Gap_Execution_Tracker_v2.md` | F4 route bootstrapped: scripts `train_f4_14day_adaptive_v1.py` (632L) + `create_f4_14day_adaptive_submissions.py` (707L) + `30_Colab_ModelGap_F4_v1.ipynb`. F4=F1(14d,291-dim)+F3(station-adaptive norm). Syntax verified. |
| 2026-02-20 | `f1_route_close_v1` | `route_decision` | `4_models/f1_14day_window_v1_20260220_112808/results.json` | F1 closed without Codabench submission: `cv_auc=0.6460` (+0.002 vs E9's 0.6441 — negligible gain). 14d window alone does NOT fix OOD covariate shift. Quota preserved; feeds F4 (14d + station-adaptive norm). |
| 2026-02-20 | `f1_14day_window_v1_20260220_112808` | `colab_full_run` | `4_models/f1_14day_window_v1_20260220_112808/results.json` | F1 full run complete: selected=`f1_f3`, `selected_q=0.002`, `cv_auc=0.6460`, `neg_precision=0.9561`, `feature_dim=291`, `k_flip=456`, `tn=436`, `fn=20`, `n_windows=228281`. |
| 2026-02-20 | `f3r_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/f3r_q00200_v1.zip` | Packed F3 short-name ZIPs from `f3_station_adaptive_v1_20260219_215436`: `base/q00010/q00020/q00050/q00100/q00200`; each ZIP contains `station_norm_stats.json` (9 training stations). Submit `f3r_q00010_v1.zip` first gate. |
| 2026-02-20 | `f3_station_adaptive_v1_20260219_215436` | `colab_full_run` | `4_models/f3_station_adaptive_v1_20260219_215436/results.json` | F3 full run complete: selected=`e9_q1`, `selected_q=0.002`, `cv_auc=0.7227` (+0.079 vs D2 — largest AUC jump in entire experiment series), `neg_precision=0.9649`, `feature_dim=165`, `k_flip=456`, `tn=440`, `fn=16`, `n_windows=228344`. |
| 2026-02-20 | `f2_route_close_v1` | `route_decision` | `4_models/f2_lambdamart_v1_20260219_165110/results.json` | F2 closed without Codabench submission: CV AUC=0.553 < D2 (0.643) and even E3 (CV=0.594). LambdaMART rank:ndcg consistently underperforms binary classification on cross-station AUC. Quota preserved. |
| 2026-02-20 | `f2_lambdamart_v1_20260219_165110` | `colab_full_run` | `4_models/f2_lambdamart_v1_20260219_165110/results.json` | F2 full run completed (selected=`f2_f3`, `n_estimators=1000`, `selected_q=0.002`, `cv_auc=0.553`, `cv_neg_precision=0.914`, `feature_dim=165`). |
| 2026-02-19 | `f_track_bootstrap_v1` | `route_plan` | `0_README/Model_Gap_Execution_Tracker_v2.md` | After E9 elimination, opened F-track with three new routes targeting root causes: F1 (14d window), F2 (LambdaMART rank:ndcg), F3 (station-adaptive normalization). All pending Colab implementation. |
| 2026-02-19 | `e9r_q00200_eval_v1` | `online_eval` | `5_outputs/submissions/e9r_q00200_v1.zip` | Codabench: `auc=0.623770`, `acc=0.886248`, `f1=0.9396452`, `mcc=0.037707`; best MCC so far (3.8× D2) but F1 below incumbent. OOD neg_precision ~41%. E9 closed. |
| 2026-02-19 | `e9r_q00100_eval_v1` | `online_eval` | `5_outputs/submissions/e9r_q00100_v1.zip` | Codabench: `auc=0.623773`, `acc=0.886736`, `f1=0.939841`, `mcc=0.030035`; MCC 3× D2 but F1 dropped below incumbent. |
| 2026-02-19 | `e9r_q00010_eval_v1` | `online_eval` | `5_outputs/submissions/e9r_q00010_v1.zip` | Codabench: `auc=0.623770`, `acc=0.886736`, `f1=0.9399652`, `mcc=0.013718`; ties D2 F1 within 0.0000025 but loses AUC tie-break (`0.6238 < 0.6434`). |
| 2026-02-19 | `e9r_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e9r_q00200_v1.zip` | Packed E9 short-name ZIPs from `e9_multihorizon_meta_official_v1_20260218_222247`: `base/q00010/q00020/q00050/q00100/q00200`. |
| 2026-02-18 | `e9_smoke_full_20260219_000036` | `local_smoke` | `tmp_rovodev_smoke/e9_smoke_full_20260219_000036/results.json` | End-to-end smoke with saved model passed (`feature_dim=165`, selected=`e9_q1`, selected_q=`0.0001`, `cv_auc=0.6876`); policy row showed `k=22`, `tn=21`, `fn=1`. |
| 2026-02-18 | `e9_smoke_test_20260218_235657` | `local_smoke` | `tmp_rovodev_smoke/e9_smoke_test_20260218_235657/cv_policy_results.csv` | First E9 quick smoke passed (`skip_save_model=True`) after fixing NaN-safe `future_max_rel` labeling; output labels/ranking stable (`feature_dim=165`, stations=9). |
| 2026-02-18 | `26_Colab_ModelGap_E9_v1` | `notebook_added` | `2_notebooks/26_Colab_ModelGap_E9_v1.ipynb` | New one-click Colab entry for E9 route (multi-horizon meta official-only + auto-pack `e9r_*` ZIPs). |
| 2026-02-18 | `create_e9_multihorizon_meta_submissions` | `script_added` | `3_src/create_e9_multihorizon_meta_submissions.py` | Added E9 portable packer with five boosters (`neg14/neg7/neg3/rel/meta`) and short-name ZIP output. |
| 2026-02-18 | `train_e9_multihorizon_meta_official_v1` | `script_added` | `3_src/train_e9_multihorizon_meta_official_v1.py` | Added E9 official-only retrain line: multi-horizon targets (14d/7d/3d) + future-max-relative regression + meta ranker under station-holdout CV. |
| 2026-02-18 | `e9_route_bootstrap_v1` | `route_plan` | `0_README/Model_Gap_Validation_Plan_v2.md` | After E8 elimination, opened E9 as next full retrain route with explicit target-diversity design; next step is Colab full run then online gate (`q00001`). |
| 2026-02-18 | `e8r946_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/e8r946_q00001_v1.zip` | Codabench: `auc=0.608640533516436`, `acc=0.8867106600290716`, `f1=0.9399540468122533`, `mcc=-0.0012819145271933659`; first E8 gate is below baseline (`0.939961`), so E8 is eliminated per gate rule. |
| 2026-02-18 | `e8r946_modelpy_full_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/pkg_e8r946_q00001/predictions.csv` | Executed packaged `model.py` (`e8r946_q00001_v1`) on synthetic full-size index (`n=77799`); output valid (`null=0`, `lt05=1`, range `[0.49, 0.99]`). |
| 2026-02-18 | `e8r946_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e8r946_q00200_v1.zip` | Packed E8 short-name ZIPs from `e8_stacked_meta_official_v1_20260218_141946`: `base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`; ready for online gate upload. |
| 2026-02-18 | `e8_stacked_meta_official_v1_20260218_141946` | `colab_full_run` | `4_models/e8_stacked_meta_official_v1_20260218_141946/results.json` | E8 full run completed and downloaded (selected=`e8_f3`, `selected_q=0.002`, `cv_auc=0.6455`, `cv_mcc=0.0173`, `feature_dim=165`, `n_windows=303370`). |
| 2026-02-18 | `e8sm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/pkg_e8sm_q00010/predictions.csv` | Executed packaged `model.py` (`e8sm_q00010_v1`) on synthetic full-size index (`n=77799`); output valid (`null=0`, `lt05=7`, range `[0.49, 0.99]`). |
| 2026-02-18 | `e8sm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e8sm_q00020_v1.zip` | E8 packer smoke passed; generated compact ZIPs (`base/q00010/q00020`) with stacked-meta portable artifacts. |
| 2026-02-18 | `e8_smoke_test_20260218_183444` | `local_smoke` | `tmp_rovodev_smoke/e8_smoke_test_20260218_183444/cv_policy_results.csv` | E8 smoke run passed end-to-end (`feature_dim=165`, model=stacked-meta over `neg1/neg2/flood` heads, selected=`e8_q1`, selected_q=`0.0001`). |
| 2026-02-18 | `25_Colab_ModelGap_E8_v1` | `notebook_added` | `2_notebooks/25_Colab_ModelGap_E8_v1.ipynb` | New one-click Colab entry for E8 route (stacked-meta official-only + auto-pack `e8r_*` ZIPs). |
| 2026-02-18 | `create_e8_stacked_meta_submissions` | `script_added` | `3_src/create_e8_stacked_meta_submissions.py` | Added E8 portable packer with four boosters (`neg1/neg2/flood/meta`) and short-name ZIP output. |
| 2026-02-18 | `train_e8_stacked_meta_official_v1` | `script_added` | `3_src/train_e8_stacked_meta_official_v1.py` | Added E8 official-only retrain line: stacked-meta ensemble over base neg/flood heads, optimized under station-holdout CV + F1-first q policy scan. |
| 2026-02-18 | `e8_route_bootstrap_v1` | `route_plan` | `0_README/Model_Gap_Validation_Plan_v2.md` | E7 closed after repeated q00005 fail; next route switched to E8 stacked-meta official-only training line and implementation completed (scripts + notebook + smoke). |
| 2026-02-18 | `e7_route_close_v1` | `route_decision` | `4_models/e7_neustg_twostage_v1_20260217_195931/results.json` | E7 closed as eliminated: `q00001/q00002` both below baseline (`0.939954 < 0.939961`) and `q00005` failed twice (`e7r931_q00005_v1.zip`, `e7r931f_q00005_v1.zip`); stop further E7 submissions. |
| 2026-02-18 | `e7r931f_q00005_eval_fail_v1` | `online_eval_fail` | `5_outputs/submissions/e7r931f_q00005_v1.zip` | User reported refreshed `q00005` package still failed on Codabench; local smoke remains valid, issue treated as platform/runtime instability for this route. |
| 2026-02-18 | `e7r931f_q00005_repack_v1` | `submission_pack_fix` | `5_outputs/submissions/e7r931f_q00005_v1.zip` | Repacked `q00005` with fresh filename after user-reported Codabench fail; local smoke passed (`rows=77799`, `null=0`, `lt05=3`). |
| 2026-02-18 | `e7r931_q00005_eval_fail_v1` | `online_eval_fail` | `5_outputs/submissions/e7r931_q00005_v1.zip` | User reported Codabench `fail` (error log not yet provided); local package structure and model.py execution are valid, likely upload/session transient issue. |
| 2026-02-18 | `e7r931_q00002_eval_v1` | `online_eval` | `5_outputs/submissions/e7r931_q00002_v1.zip` | Codabench: `auc=0.6005523252805567`, `acc=0.8867106600290716`, `f1=0.9399540468122533`, `mcc=-0.0012819145271933659`; identical to `q00001`, still below baseline (`0.939961`), so E7 now only needs `q00005` final gate. |
| 2026-02-18 | `e7r931_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/e7r931_q00001_v1.zip` | Codabench: `auc=0.6005523252805567`, `acc=0.8867106600290716`, `f1=0.9399540468122533`, `mcc=-0.0012819145271933659`; first E7 gate is below baseline (`0.939961`), currently back on all-ones plateau; continue `q00002/q00005` before final route decision. |
| 2026-02-18 | `e7r931_modelpy_full_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/e7_fake_preds_full.csv` | Executed packaged `model.py` (`e7r931_q00001_v1`) on synthetic full-size index (`n=77799`); output valid (`null=0`, `lt05=1`, `min=0.49`, `max=0.9891`). |
| 2026-02-18 | `e7r931_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e7r931_q00200_v1.zip` | Packed E7 short-name ZIPs from `e7_neustg_twostage_v1_20260217_195931`: `base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`; ready for online gate upload. |
| 2026-02-18 | `e7_neustg_twostage_v1_20260217_195931` | `colab_full_run` | `4_models/e7_neustg_twostage_v1_20260217_195931/results.json` | E7 full run completed and downloaded (selected=`e7_q2`, `selected_q=0.002`, `flood_gate=0.8`, `safe_blend=0.45`, `cv_auc=0.8175`, `cv_mcc=0.0140`, `feature_dim=165`, `n_windows=303370`). |
| 2026-02-18 | `e7sm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/e7_fake_preds.csv` | Executed packaged `model.py` (`e7sm_q00010_v1`) on synthetic full-flow index (`n=360`); output valid (`null=0`, `lt05=1`, range `[0.49, 0.9886]`). |
| 2026-02-18 | `e7sm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e7sm_q00020_v1.zip` | E7 packer smoke passed; generated compact ZIPs (`base/q00010/q00020`) from two-stage artifacts (`flood_booster + safe_booster`). |
| 2026-02-18 | `e7_smoke_test_20260218_013618` | `local_smoke` | `tmp_rovodev_smoke/e7_smoke_test_20260218_013618/cv_policy_results.csv` | E7 smoke run passed end-to-end on official `NEUSTG` (`feature_dim=165`, stations=12, eval_stations=3 holdout, selected=`e7_q1`, selected_q=`0.0002`, selected_flood_gate=`0.85`). |
| 2026-02-18 | `24_Colab_ModelGap_E7_v1` | `notebook_added` | `2_notebooks/24_Colab_ModelGap_E7_v1.ipynb` | New one-click Colab entry for E7 route (NEUSTG-first + two-stage decision + auto-pack `e7r_*` ZIPs). |
| 2026-02-18 | `create_e7_neustg_twostage_submissions` | `script_added` | `3_src/create_e7_neustg_twostage_submissions.py` | Added E7 portable packer with two-stage runtime (`flood_booster + safe_booster`) and short-name ZIP output. |
| 2026-02-18 | `train_e7_neustg_twostage_v1` | `script_added` | `3_src/train_e7_neustg_twostage_v1.py` | Added E7 official-only retrain line: NEUSTG 12-station training source + stage-1 flood gate + stage-2 safe ranking policy. |
| 2026-02-17 | `e6r853_q00005_eval_v1` | `online_eval` | `5_outputs/submissions/e6r853_q00005_v1.zip` | Codabench: `auc=0.6658595085725095`, `acc=0.8867106600290716`, `f1=0.939953228016827`, `mcc=0.004313407185879859`; slightly higher MCC than `q00001/q00002` but lower F1, so E6 cannot replace D2 under F1-first rule. |
| 2026-02-17 | `e6r853_q00002_eval_v1` | `online_eval` | `5_outputs/submissions/e6r853_q00002_v1.zip` | Codabench: `auc=0.6658594739775017`, `acc=0.8867106600290716`, `f1=0.9399540468122533`, `mcc=-0.0012819145271933659`; identical to `q00001`, still below D2 under F1-first objective. |
| 2026-02-17 | `e6r853_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/e6r853_q00001_v1.zip` | Codabench: `auc=0.6658594739775017`, `acc=0.8867106600290716`, `f1=0.9399540468122533`, `mcc=-0.0012819145271933659`; AUC improved but first flip likely hit FN (`TN=0/FN=1` pattern), so F1-first objective did not improve. |
| 2026-02-17 | `e6r853_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e6r853_q00200_v1.zip` | Packed E6 short-name ZIPs from `e6_marginreg_official_v1_20260217_124853`: `base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`; ready for online gate upload. |
| 2026-02-17 | `e6_marginreg_official_v1_20260217_124853` | `colab_full_run` | `4_models/e6_marginreg_official_v1_20260217_124853/results.json` | E6 full run completed (`selected_cfg=e6_q3`, `selected_q=0.002`, `selected_auc=0.66145`, `selected_mcc=0.02319`, `selection_mode=station_quota`, `feature_dim=165`); next step is online F1-first gate on `e6r853_*`. |
| 2026-02-17 | `e6r853_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/pkg_e6r853_q00001/predictions.csv` | Executed packaged `model.py` (`e6r853_q00001_v1`) on full-size synthetic index (`n=77739`); output valid (`null=0`, `lt05=1`, range `[0.49, 0.99]`). |
| 2026-02-17 | `e6sm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/pkg_e6sm_q00001/predictions.csv` | Executed packaged `model.py` (`e6sm_q00001_v1`) on full-size synthetic index (`n=77739`); output valid (`null=0`, `lt05=1`, range `[0.49, 0.99]`). |
| 2026-02-17 | `e6sm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e6sm_q00002_v1.zip` | E6 packer smoke passed; generated compact ZIPs (`q00001/q00002`) from margin-regression artifacts. |
| 2026-02-17 | `e6_smoke_test_20260217_161651` | `local_smoke` | `tmp_rovodev_smoke/e6_smoke_test_20260217_161651/cv_policy_results.csv` | E6 smoke run passed end-to-end (`feature_dim=165`, selected=`e6_q3`, selected_q=`0.00005`, `auc=0.6632`); new objective uses margin regression + uncertainty penalty ranking. |
| 2026-02-17 | `23_Colab_ModelGap_E6_v1` | `notebook_added` | `2_notebooks/23_Colab_ModelGap_E6_v1.ipynb` | New one-click Colab entry for E6 route (margin regression + uncertainty ranker + auto-pack `e6r_*` ZIPs). |
| 2026-02-17 | `create_e6_marginreg_submissions` | `script_added` | `3_src/create_e6_marginreg_submissions.py` | Added E6 portable packer with dual-booster runtime (`margin_booster + unc_booster`) and short-name ZIP output. |
| 2026-02-17 | `train_e6_marginreg_official_v1` | `script_added` | `3_src/train_e6_marginreg_official_v1.py` | Added E6 official-only retrain line: direct `future_max_rel` regression + residual-uncertainty model, with risk-adjusted non-flood ranking. |
| 2026-02-17 | `e5r752_q00005_eval_v1` | `online_eval` | `5_outputs/submissions/e5r752_q00005_v1.zip` | Codabench: `auc=0.6248284931891604`, `acc=0.8867363871415892`, `f1=0.9399668641635247`, `mcc=0.010847184026220352`; MCC rose slightly but F1 dropped below `q00001/q00002`, so E5 route cannot replace D2 under F1-first rule. |
| 2026-02-17 | `e5r752_q00002_eval_v1` | `online_eval` | `5_outputs/submissions/e5r752_q00002_v1.zip` | Codabench: `auc=0.6248285623791763`, `acc=0.8867363871415892`, `f1=0.939967682773009`, `mcc=0.010034773348060445`; identical to `q00001`, still below D2 on AUC tie-break. |
| 2026-02-17 | `e5r752_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/e5r752_q00001_v1.zip` | Codabench: `auc=0.6248285623791763`, `acc=0.8867363871415892`, `f1=0.939967682773009`, `mcc=0.010034773348060445`; ties incumbent on F1/MCC but loses AUC tie-break to `d2s2_q00001_v1` (`0.6248 < 0.6434`). |
| 2026-02-17 | `e5r752_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e5r752_q00200_v1.zip` | Packed E5 short-name ZIPs from `e5_robustneg_official_v1_20260217_051752`: `base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`; ready for online gate upload. |
| 2026-02-17 | `e5_robustneg_official_v1_20260217_051752` | `colab_full_run` | `4_models/e5_robustneg_official_v1_20260217_051752/results.json` | E5 full run completed (`selected_cfg=e5_q1`, `selected_q=0.002`, `selected_auc=0.6551`, `selected_mcc=0.0237`, `selection_mode=station_quota`, `feature_dim=165`); next step is online F1-first gate on `e5r752_*`. |
| 2026-02-17 | `e5sm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/pkg_e5sm_q00001/predictions.csv` | Executed packaged `model.py` (`e5sm_q00001_v1`) on full-size synthetic index (`n=77739`); output valid (`null=0`, `lt05=1`, range `[0.49, 0.99]`). |
| 2026-02-17 | `e5sm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e5sm_q00002_v1.zip` | E5 packer smoke passed; generated compact ZIPs (`q00001/q00002`) from robust-negative artifacts. |
| 2026-02-17 | `e5_smoke_test_20260217_111346` | `local_smoke` | `tmp_rovodev_smoke/e5_smoke_test_20260217_111346/cv_policy_results.csv` | E5 smoke run passed end-to-end (`feature_dim=165`, selected=`e5_q2`, selected_q=`0.0001`, `auc=0.6647`); fixed NaN labeling issue by skipping invalid future windows. |
| 2026-02-17 | `22_Colab_ModelGap_E5_v1` | `notebook_added` | `2_notebooks/22_Colab_ModelGap_E5_v1.ipynb` | New one-click Colab entry for E5 route (robust-negative objective + station-quota policy + auto-pack `e5r_*` ZIPs). |
| 2026-02-17 | `create_e5_robustneg_submissions` | `script_added` | `3_src/create_e5_robustneg_submissions.py` | Added E5 portable packer with short-name ZIP output and CodeBench-safe fallback behavior. |
| 2026-02-17 | `train_e5_robustneg_official_v1` | `script_added` | `3_src/train_e5_robustneg_official_v1.py` | Added E5 official-only retrain line: robust-negative target, uncertain band down-weighting, and explicit NaN-safe future-window handling. |
| 2026-02-17 | `e4r013_q00100_eval_v1` | `online_eval` | `5_outputs/submissions/e4r013_q00100_v1.zip` | Codabench: `auc=0.6222458934811339`, `acc=0.886144663553686`, `f1=0.9396227702172653`, `mcc=0.009390337378789835`; final E4 gate also below baseline `0.939961`, so E4 route is closed. |
| 2026-02-17 | `e4r013_q00050_eval_v1` | `online_eval` | `5_outputs/submissions/e4r013_q00050_v1.zip` | Codabench: `auc=0.6222482039334465`, `acc=0.8865177066851901`, `f1=0.9398365999699934`, `mcc=0.012294575420919203`; improved vs `q00500` but still below baseline `0.939961`, so final E4 gate now depends on `q00100`. |
| 2026-02-17 | `e4r013_q00500_eval_v1` | `online_eval` | `5_outputs/submissions/e4r013_q00500_v1.zip` | Codabench: `auc=0.6222345825609352`, `acc=0.8836877243082623`, `f1=0.9381887287741654`, `mcc=0.0184585667329753`; first E4 gate at larger q underperformed baseline `0.939961`, so next check must move to smaller q (`q00050/q00100`). |
| 2026-02-17 | `e4r013_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e4r013_q02000_v1.zip` | Packed short-name E4 ZIPs from `e4_stationblend_official_v1_20260216_191013`: `base/q00050/q00100/q00200/q00500/q01000/q01500/q02000`; ready for online gate. |
| 2026-02-17 | `e4_stationblend_official_v1_20260216_191013` | `colab_full_run` | `4_models/e4_stationblend_official_v1_20260216_191013/results.json` | E4 full run completed (`selected_cfg=e4_q3`, `selected_q=0.02`, `selected_auc=0.7944`, `selected_mcc=0.0905`, `station_model_count=9`); next step is online F1-first gate on `e4r013_*`. |
| 2026-02-17 | `e4sm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/e4_fake_preds.csv` | Executed packaged `model.py` (`e4sm_q00100_v1`) on full-size synthetic index (`n=77739`); output valid (`null=0`, `lt05=77`, range `[0.49, 0.99]`). |
| 2026-02-17 | `e4sm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e4sm_q00200_v1.zip` | E4 packer smoke passed; generated compact ZIPs (`base/q00100/q00200`) with global+station artifacts. |
| 2026-02-17 | `e4_smoke_test_20260217_000240` | `local_smoke` | `tmp_rovodev_smoke/e4_smoke_test_20260217_000240/results.json` | E4 smoke run passed end-to-end (`model=global+station blend`, `feature_dim=165`, `station_model_count=9`, selected=`e4_q1`, selected_q=`0.002`, `cv_auc=0.7578`). |
| 2026-02-17 | `21_Colab_ModelGap_E4_v1` | `notebook_added` | `2_notebooks/21_Colab_ModelGap_E4_v1.ipynb` | New one-click Colab entry for E4 route (station-blend retrain + auto-pack `e4r_*` ZIPs). |
| 2026-02-17 | `create_e4_stationblend_submissions` | `script_added` | `3_src/create_e4_stationblend_submissions.py` | Added E4 portable packer: global booster + station boosters blended at inference, with station-quota/global q-policy support. |
| 2026-02-17 | `train_e4_stationblend_official_v1` | `script_added` | `3_src/train_e4_stationblend_official_v1.py` | Added E4 training line: official-only hourly features, global non-flood ranker + station-specialist rankers, time-based CV policy selection. |
| 2026-02-16 | `e3b256_q00002_m1015_eval_v1` | `online_eval` | `5_outputs/submissions/e3b256_q00002_m1015_v1.zip` | Codabench: `auc=0.5472339628984487`, `acc=0.8867106600290716`, `f1=0.9399540468122533`, `mcc=-0.0012819145271933659`; identical to `q00001_m1015`, still below baseline `0.939961`. |
| 2026-02-16 | `e3b256_q00001_m1015_eval_v1` | `online_eval` | `5_outputs/submissions/e3b256_q00001_m1015_v1.zip` | Codabench: `auc=0.5472339628984487`, `acc=0.8867106600290716`, `f1=0.9399540468122533`, `mcc=-0.0012819145271933659`; first E3b gate did not improve over E3 and remains below baseline `0.939961`. |
| 2026-02-16 | `e3b256_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e3b256_q00005_m1015_v1.zip` | Generated E3b production ZIPs from `e3_rankpair_official_v1_20260216_074256` using stage-2 veto grid (`q00001/q00002/q00005` x `m24={0.05,0.10}` x `m72={0.10,0.15}`). |
| 2026-02-16 | `e3bsm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/e3b_fake_preds.csv` | Executed packaged `model.py` (`e3bsm_q00001_m1015_v1`) on full-size synthetic index (`n=77781`); output valid (`null=0`, `lt05=1`) confirming stage-2 veto policy works end-to-end. |
| 2026-02-16 | `e3bsm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e3bsm_q00005_m1015_v1.zip` | E3b veto packer smoke passed; generated compact ZIPs across `(q, margin24, margin72)` grid from E3 run artifacts without retraining. |
| 2026-02-16 | `20_Colab_ModelGap_E3b_v1` | `notebook_added` | `2_notebooks/20_Colab_ModelGap_E3b_v1.ipynb` | New Colab entry for E3b post-training policy route (rankpair top-q + 24h/72h safety veto), outputs `e3b*` ZIPs. |
| 2026-02-16 | `create_e3b_rankpair_veto_submissions` | `script_added` | `3_src/create_e3b_rankpair_veto_submissions.py` | Added E3b packer: two-stage decision policy using recent sea-level relative-to-threshold veto on top of E3 rank score. |
| 2026-02-16 | `e3r256_q00005_eval_v1` | `online_eval` | `5_outputs/submissions/e3r256_q00005_v1.zip` | Codabench: `auc=0.547234`, `acc=0.886711`, `f1=0.939953`, `mcc=0.004313`; below baseline (`0.939961`), E3 route closed. |
| 2026-02-16 | `e3r256_q00002_eval_v1` | `online_eval` | `5_outputs/submissions/e3r256_q00002_v1.zip` | Codabench: `auc=0.547234`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; identical to `q00001`, still below baseline `0.939961`. |
| 2026-02-16 | `e3r256_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/e3r256_q00001_v1.zip` | Codabench: `auc=0.547234`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; first E3 online gate is below baseline (`0.939961`) and below D2 incumbent. |
| 2026-02-16 | `e3r256_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e3r256_q01000_v1.zip` | Packed E3 short-name ZIPs from `e3_rankpair_official_v1_20260216_074256` with conservative ultra-small q grid (`q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200/q00300/q00500/q01000`) for online gate. |
| 2026-02-16 | `e3_rankpair_official_v1_20260216_074256` | `colab_full_run` | `4_models/e3_rankpair_official_v1_20260216_074256/results.json` | E3 full run completed (`model=XGBRanker pairwise`, selected=`e3_f5`, `selected_q=0.01`, `cv_auc=0.5939`, `cv_mcc=0.0331`); waiting online evaluation on `e3r256_*` packages. |
| 2026-02-16 | `e3sm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/e3_fake_preds_full.csv` | Executed packaged `model.py` (`e3sm_q00100_v1`) on full-size synthetic index (`n=77781`); output valid (`null=0`, `lt05=77`, range `[0.49, 0.99]`). |
| 2026-02-16 | `e3sm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e3sm_q00500_v1.zip` | E3 artifacts packed via portable booster flow (`booster.json + scaler_stats.npz + inference_meta.json`), zip structure validated. |
| 2026-02-16 | `e3_smoke_test_20260216_124212` | `local_smoke` | `tmp_rovodev_smoke/e3_smoke_test_20260216_124212/results.json` | E3 quick+cap run passed end-to-end (`model=XGBRanker pairwise`, `feature_dim=165`, selected=`e3_q1`, `selected_q=0.005`, `cv_auc=0.6010`). |
| 2026-02-16 | `19_Colab_ModelGap_E3_v1` | `notebook_added` | `2_notebooks/19_Colab_ModelGap_E3_v1.ipynb` | New one-click Colab entry for E3 route (rankpair objective, official-only, auto-pack `e3r_*` ZIPs). |
| 2026-02-16 | `train_e3_rankpair_official_v1` | `script_added` | `3_src/train_e3_rankpair_official_v1.py` | Added post-E2 new line: XGBRanker(pairwise) for direct non-flood ranking with same official-hourly feature stack and F1-first q policy scan. |
| 2026-02-16 | `e2r523f_q00500_eval_v1` | `online_eval` | `5_outputs/submissions/e2r523f_q00500_v1.zip` | Codabench: `auc=0.628305`, `acc=0.883276`, `f1=0.937970`, `mcc=0.009243`; below baseline (`0.939961`), E2 fails at `q=0.005`. |
| 2026-02-16 | `e2r523f_q00200_eval_v1` | `online_eval` | `5_outputs/submissions/e2r523f_q00200_v1.zip` | Codabench: `auc=0.628288`, `acc=0.885244`, `f1=0.939113`, `mcc=0.002222`; below baseline (`0.939961`), E2 fails at `q=0.002`. |
| 2026-02-16 | `e2r523f_q00100_eval_v1` | `online_eval` | `5_outputs/submissions/e2r523f_q00100_v1.zip` | Codabench: `auc=0.628295`, `acc=0.886170`, `f1=0.939636`, `mcc=0.010681`; still below baseline (`0.939961`), so E2 remains behind D2 on F1-first gate. |
| 2026-02-16 | `e2r523f_q01500_eval_v1` | `online_eval` | `5_outputs/submissions/e2r523f_q01500_v1.zip` | Codabench: `auc=0.628365`, `acc=0.877127`, `f1=0.934353`, `mcc=0.026019`; below baseline (`0.939961`), indicating `q=0.015` over-flips and introduces too many FN for F1-first objective. |
| 2026-02-16 | `e2r523f_submission_pack_refresh_v1` | `submission_pack` | `5_outputs/submissions/e2r523f_q02000_v1.zip` | Refreshed compact E2 pack with denser small-q grid (`q00100/q00200/q00500/q01000/q01500/q02000`) to continue online gate from conservative q values. |
| 2026-02-16 | `e2r523_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e2r523_q04000_v1.zip` | Packed E2 short-name ZIPs from `e2_official_hourly_v1_20260215_185023`: `base/q00500/q01000/q01500/q02000/q03000/q04000`; ready for Codabench gate upload. |
| 2026-02-16 | `e2_official_hourly_v1_20260215_185023` | `colab_full_run` | `4_models/e2_official_hourly_v1_20260215_185023/results.json` | E2 full run completed (`feature_dim=165`, selected=`e2_q2`, selected_q=`0.04`, selected_auc=`0.6612`, selected_mcc=`0.0989`); next step is online F1-first gate on packaged `e2r523_*` submissions. |
| 2026-02-16 | `e2sm_modelpy_smoke_v1` | `local_smoke` | `tmp_rovodev_smoke/e2_fake_preds.csv` | Executed packaged `model.py` from `e2sm_q01000_v1` on synthetic test-index (`n=300`); output valid (`null=0`, `lt05=3`, range `[0.49, 0.99]`). |
| 2026-02-16 | `e2sm_submission_pack_v1` | `local_smoke` | `tmp_rovodev_smoke/submissions/e2sm_q01000_v1.zip` | New E2 packer smoke passed; produced portable ZIPs (`e2sm_base_v1.zip`, `e2sm_q01000_v1.zip`) with `booster.json + scaler_stats.npz + inference_meta.json`. |
| 2026-02-16 | `e2_smoke_test_20260216_010757` | `local_smoke` | `tmp_rovodev_smoke/e2_smoke_test_20260216_010757/results.json` | E2 quick+cap run passed end-to-end (`feature_dim=165`, selected=`e2_q3`, selected_q=`0.02`, selected_mcc=`0.0690`, selected_auc=`0.6523`). |
| 2026-02-16 | `18_Colab_ModelGap_E2_v1` | `notebook_added` | `2_notebooks/18_Colab_ModelGap_E2_v1.ipynb` | One-click Colab entry for E2 (official-only hourly richer features + wider q grid + auto-pack `e2r_*` ZIPs). |
| 2026-02-16 | `create_e2_official_hourly_submissions` | `script_added` | `3_src/create_e2_official_hourly_submissions.py` | Added portable E2 packer using `booster.json` artifacts with station-quota/global policy support and short-name ZIP output. |
| 2026-02-15 | `e1r3_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/e1r3_q00001_v1.zip` | Codabench: `auc=0.5000568`, `acc=0.886736`, `f1=0.9399677`, `mcc=0.010035`; same as `e1r2_q00001`, no improvement over D2 tie-break (`auc=0.643427`), so E1 route closed. |
| 2026-02-15 | `e1r3_submission_pack_v1` | `submission_pack_fix` | `5_outputs/submissions/e1r3_q00001_v1.zip` | Repacked E1 with portable booster artifacts (`booster.json` + `scaler_stats.npz` + `inference_meta.json`) to avoid cross-version pickle issues on Codabench. |
| 2026-02-15 | `e1r2_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/e1r2_q00001_v1.zip` | Codabench: `auc=0.5000568`, `acc=0.886736`, `f1=0.9399677`, `mcc=0.010035`; ties incumbent on F1/MCC but loses AUC tie-break heavily, indicating likely fallback/randomized ranking in runtime. |
| 2026-02-15 | `e1r2_submission_pack_v1` | `submission_pack_fix` | `5_outputs/submissions/e1r2_q00001_v1.zip` | Hardened E1 submission template (arg/column fallback + exception-safe prediction output) and regenerated `e1r2_*` ZIPs to reduce ingestion/runtime failure risk. |
| 2026-02-15 | `e1r_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/e1r_q00001_v1.zip` | Packed E1 short-name ZIPs from `e1_negexpert_xgb_v1_20260215_141215` (`base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200/q00500`), ready for online gate. |
| 2026-02-15 | `e1_negexpert_xgb_v1_20260215_141215` | `colab_full_run` | `4_models/e1_negexpert_xgb_v1_20260215_141215/results.json` | E1 full run completed (`selection_mode=station_quota`, `neg_target_rate=0.1133`, selected=`e1_q1`, `n_days=3`, `cv_selected_q=0.005`, `pooled_auc=0.6581`). |
| 2026-02-15 | `17_Colab_ModelGap_E1_v1` | `notebook_added` | `2_notebooks/17_Colab_ModelGap_E1_v1.ipynb` | New one-click Colab entry for E1 route (negative-expert retrain, prior-shift target, station-quota selection, auto-pack `e1r_*` ZIPs). |
| 2026-02-15 | `train_e1_negexpert_xgb_v1` | `script_added` | `3_src/train_e1_negexpert_xgb_v1.py` | Added E1 training pipeline: dedicated non-flood expert under prior shift (`neg_target_rate`), with global/station-quota policy search and F1-first selection. |
| 2026-02-15 | `create_e1_negexpert_submissions` | `script_added` | `3_src/create_e1_negexpert_submissions.py` | Added E1 packer: short-name ZIPs (`e1r_base/q*`) with default flood + top non-flood expert flips; CodeBench-compatible `model.py` template. |
| 2026-02-15 | `e1_smoke_test2_20260215_215117` | `local_smoke` | `tmp_rovodev_smoke/e1_smoke_test2_20260215_215117/results.json` | Smoke CV passed (`skip_save_model=True`): all configs completed and selected row generated without runtime errors. |
| 2026-02-15 | `e1_smoke_full_20260215_215210` | `local_smoke` | `tmp_rovodev_smoke/e1_smoke_full_20260215_215210/model.pkl` | End-to-end smoke passed with saved model + packer; generated sample ZIPs `tmp_rovodev_smoke/submissions/e1sm_base_v1.zip`, `e1sm_q00010_v1.zip`. |
| 2026-02-15 | `d2s2_q00005_eval_v1` | `online_eval` | `5_outputs/submissions/d2s2_q00005_v1.zip` | Codabench: `auc=0.643427`, `acc=0.886711`, `f1=0.9399532`, `mcc=0.004313`; degraded vs `d2s2_q00001_v1`, so D2 best stays at `q00001`. |
| 2026-02-15 | `d2s2_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/d2s2_q00001_v1.zip` | Codabench: `auc=0.643427`, `acc=0.886736`, `f1=0.9399677`, `mcc=0.010035`; ties A1 on F1/MCC and wins by AUC tie-break, so D2 promoted as current best candidate. |
| 2026-02-15 | `d2s2_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/d2s2_q00001_v1.zip` | New D2 route packed from 5 source runs using station-quota consensus (station negative-prior alpha=`2.0`), short-name ZIPs: `d2s2_base/q00001/q00002/q00005/q00010/q00020/q00050`; local smoke passed (`n=77739`; `base lt05=0`, `q00001 lt05=1`, `q00050 lt05=38`). |
| 2026-02-15 | `create_station_quota_consensus_submissions` | `script_added` | `3_src/create_station_quota_consensus_submissions.py` | Added D2 combo route: station-aware quota allocation over consensus low-risk ranks, then tiny-q flips; designed to avoid repeatedly selecting the same global row. |
| 2026-02-15 | `d2s2_vs_a1_rowdiff_v1` | `local_diagnostic` | `tmp_rovodev_smoke/d2s2/d2s2_q00001_v1.pred.csv` | Verified D2 changes the flipped row vs A1 (`D2 id=16141`, `A1 id=63239`; binary diff=2), so this is a genuine new decision policy. |
| 2026-02-15 | `d1c_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/d1c_q00001_v1.zip` | Codabench: `auc=0.643426`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; below baseline (`0.939961`), so D1 gate failed. |
| 2026-02-15 | `d1c_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/d1c_q00001_v1.zip` | New D1 route packed from 5 source runs (`A1/A2/B1/B2/A3`) via consensus low-risk rank (`mean rank`) with short-name ZIPs: `d1c_base/q00001/q00002/q00005/q00010/q00020/q00050`. Local smoke passed (`n=77739`; `base lt05=0`, `q00001 lt05=1`, `q00050 lt05=38`). |
| 2026-02-15 | `create_consensus_f1push_submissions` | `script_added` | `3_src/create_consensus_f1push_submissions.py` | Added D1 combo route: multi-run consensus ranking at inference (not single-model tiny-q), then force lowest-q negatives. |
| 2026-02-15 | `plateau_diagnostic_v1` | `local_diagnostic` | `tmp_rovodev_smoke/cmp_A1.csv` | Verified no key mismatch (`station|hist_end` unique=rows=77739); bottleneck is policy compression: A1/C2/A3 binary outputs differ by only 2 rows at threshold 0.5, so most backbone changes are washed out online. |
| 2026-02-15 | `a3r_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/a3r_q00001_v1.zip` | Codabench: `auc=0.387470`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; below baseline (`0.939961`), so A3 marked eliminated. |
| 2026-02-15 | `a3r_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/a3r_q00001_v1.zip` | Packed A3 short-name ZIPs from `a3_focal_xgb_v1_20260215_122316` (`base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`), local smoke passed (`n=77739`; `base lt05=0`, `q00001 lt05=1`, `q00050 lt05=38`). |
| 2026-02-15 | `a3_focal_xgb_v1_20260215_122316` | `colab_full_run` | `4_models/a3_focal_xgb_v1_20260215_122316/results.json` | A3 full run completed (`label_mode=official`, `weight_mode=focal_cb`, selected=`fr_f6`, `n_days=2`, `q=0.01`, `pooled_auc=0.3812`). Online gate (`a3r_q00001_v1.zip`) returned below-baseline F1. |
| 2026-02-15 | `a3_smoke_20260215_183637` | `local_smoke` | `4_models/a3_smoke_20260215_183637/results.json` | A3 focal-CB smoke passed (`label_mode=official`, `weight_mode=focal_cb`, selected=`fr_q2`, `q=0.002`, pooled_auc=`0.5734`, runtime~61s, `skip_save_model=True`). |
| 2026-02-15 | `16_Colab_ModelGap_A3_v1` | `notebook_added` | `2_notebooks/16_Colab_ModelGap_A3_v1.ipynb` | New one-click Colab entry for A3 (`focal_cb`, official labels, full mode, auto-pack `a3r_*` ZIPs). |
| 2026-02-15 | `f1push_focalcb_upgrade_v1` | `script_upgrade` | `3_src/train_f1push_ranker_v1.py` | Added A3 route via `--weight_mode focal_cb` (two-stage focal + class-balanced weighting with `--focal_gamma/--cb_beta/--focal_w_clip_*`). |
| 2026-02-15 | `c2r_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/c2r_q00001_v1.zip` | Codabench: `auc=0.635056`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; below baseline (`0.939961`), so C2 marked eliminated. |
| 2026-02-15 | `c2r_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/c2r_q00001_v1.zip` | Packed C2 short-name ZIPs from `c2_tcn_v1_20260215_092620` (`base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`), local smoke passed (`n=77739`; `base lt05=0`, `q00001 lt05=1`, `q00050 lt05=38`). |
| 2026-02-15 | `c2_tcn_v1_20260215_092620` | `colab_quick_run` | `4_models/c2_tcn_v1_20260215_092620/results.json` | C2 quick run completed (`label_mode=official`, selected=`c2_q1`, `n_days=3`, `q=0.01`, `pooled_auc=0.6230`). Online gate (`c2r_q00001_v1.zip`) returned below-baseline F1. |
| 2026-02-15 | `c2_preflight_local_20260215` | `local_preflight` | `3_src/train_c2_tcn_ranker_v1.py` | Preflight passed (`--help` + `py_compile`) for both C2 trainer and packer; ready for Colab full run via `2_notebooks/15_Colab_ModelGap_C2_v1.ipynb`. |
| 2026-02-15 | `15_Colab_ModelGap_C2_v1` | `notebook_added` | `2_notebooks/15_Colab_ModelGap_C2_v1.ipynb` | Dedicated C2 Colab entry (Temporal CNN backbone, `RUN_MODE=quick`, `LABEL_MODE=official`, auto-packs `c2r_*` ZIPs). |
| 2026-02-15 | `train_c2_tcn_ranker_v1` | `script_added` | `3_src/train_c2_tcn_ranker_v1.py` | Added C2 training pipeline (official-label temporal-CNN ranker + same F1-first quantile policy search protocol). |
| 2026-02-15 | `create_c2_tcn_submissions` | `script_added` | `3_src/create_c2_tcn_submissions.py` | Added C2 submission packer with torch-missing fallback (avoids ingestion crash; still emits predictions.csv). |
| 2026-02-15 | `c1d603_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/c1d603_q00001_v1.zip` | Codabench: `auc=0.626763`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; below baseline (`0.939961`), so C1 marked eliminated. |
| 2026-02-15 | `c1d603_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/c1d603_q00001_v1.zip` | Packed distilled C1 short-name ZIPs from `c1_distill_xgb_v1_20260215_152603` (`base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`), local smoke passed (`n=77739`; `base lt05=0`, `q00001 lt05=1`, `q00050 lt05=38`). |
| 2026-02-15 | `c1_distill_xgb_v1_20260215_152603` | `compat_distill_run` | `4_models/c1_distill_xgb_v1_20260215_152603/model.pkl` | Distilled CatBoost teacher to XGB regressor for Codabench compatibility (fit corr=`0.9970`, mae=`0.012047`). |
| 2026-02-15 | `c1r429_q00001_ingestion_fail_v1` | `online_eval_fail` | `5_outputs/submissions/c1r429_q00001_v1.zip` | Codabench ingestion failed: `ModuleNotFoundError: No module named 'catboost'`; no `predictions.csv` generated. |
| 2026-02-15 | `distill_catboost_bundle_to_xgb` | `script_added` | `3_src/distill_catboost_bundle_to_xgb.py` | Added compatibility distillation tool to replace CatBoost model object in bundle with XGB regressor while keeping same feature pipeline. |
| 2026-02-15 | `c1r429_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/c1r429_q00001_v1.zip` | Packed C1 short-name ZIPs from `c1_catboost_v1_20260215_064429` (`base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`), local smoke passed (`n=77739`; `base lt05=0`, `q00001 lt05=1`, `q00050 lt05=38`). |
| 2026-02-15 | `c1_catboost_v1_20260215_064429` | `colab_full_run` | `4_models/c1_catboost_v1_20260215_064429/results.json` | C1 full run completed (`label_mode=official`, `weight_mode=spw`, selected=`fr_f7`, `n_days=1`, `q=0.01`, `pooled_auc=0.6727`). |
| 2026-02-15 | `14_Colab_ModelGap_C1_v1` | `notebook_added` | `2_notebooks/14_Colab_ModelGap_C1_v1.ipynb` | Dedicated C1 Colab entry (CatBoost backbone, `RUN_MODE=full`, `LABEL_MODE=official`, `WEIGHT_MODE=spw`). |
| 2026-02-15 | `train_catboost_ranker_v1` | `script_added` | `3_src/train_catboost_ranker_v1.py` | Added CatBoost counterpart of f1-push ranker pipeline for backbone-swap validation (C1). |
| 2026-02-15 | `b3n254_b037_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/b3n254_b037_q00001_v1.zip` | Codabench: `auc=0.614123`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; below baseline (`0.939961`), so B3 marked eliminated. |
| 2026-02-15 | `b3n254_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/b3n254_b037_q00001_v1.zip` | Packed B3 short-name ZIPs from `negmine_v1_20260215_061254` (`base/b012/b020/b027/b037/b037_q00001/b037_q00002/b037_q00005`), local smoke passed (`n=77739`; `b037 lt05=0`, `b037_q00001 lt05=1`, `b037_q00005 lt05=3`). |
| 2026-02-15 | `negmine_v1_20260215_061254` | `colab_full_run` | `4_models/negmine_v1_20260215_061254/results.json` | B3 full run completed (`label_mode=official`, selected=`nm_q1`, `training_samples=233217`, `flood_rate=0.2142`). |
| 2026-02-15 | `create_negmine_submissions_v1` | `script_added` | `3_src/create_negmine_submissions.py` | Added reusable packer for negmine runs (bias sweep + tiny-q rank-selective variants with short names). |
| 2026-02-14 | `13_Colab_ModelGap_B3_v1` | `notebook_added` | `2_notebooks/13_Colab_ModelGap_B3_v1.ipynb` | Dedicated B3 Colab entry (safe mount fallback, `RUN_MODE=full`, `LABEL_MODE=official`, `MAX_TRAIN_SAMPLES=0`). |
| 2026-02-14 | `b2r826_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/b2r826_q00001_v1.zip` | Codabench: `auc=0.653809`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; below baseline (`0.939961`), so B2 marked eliminated. |
| 2026-02-14 | `b2r826_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/b2r826_q00001_v1.zip` | Packed B2 short-name ZIPs from `b2_union_xgb_v1_20260214_130826` (`base/q00001/q00002/q00005/q00010/q00020/q00050/q00100/q00200`), local smoke passed (`n=77739`; `base lt05=0`, `q00001 lt05=1`, `q00050 lt05=38`). |
| 2026-02-14 | `b2_union_xgb_v1_20260214_130826` | `colab_full_run` | `4_models/b2_union_xgb_v1_20260214_130826/results.json` | B2 full run completed (`label_mode=union`, `weight_mode=spw`, `selection_mode=f1_first`, selected=`fr_q3`, `n_days=3`, `q=0.01`, `pooled_auc=0.8268`). |
| 2026-02-14 | `colab_notebook_syntax_fix_08_12_v1` | `notebook_fix` | `2_notebooks/12_Colab_ModelGap_B2_v1.ipynb` | Fixed broken code cells in `08~12` (submission pack cmd + tracking write cell) so Colab can run end-to-end without syntax errors. |
| 2026-02-14 | `b1r519_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/b1r519_q00001_v1.zip` | Codabench: `auc=0.637045`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; below baseline (`0.939961`), so B1 marked eliminated. |
| 2026-02-14 | `b1r519_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/b1r519_q00750_v1.zip` | Packed B1 short-name ZIPs from `b1_groupdro_xgb_v1_20260214_122519` (`base/q00001/q00005/q00010/q00020/q00050/q00750`), local smoke passed. |
| 2026-02-14 | `b1_groupdro_xgb_v1_20260214_122519` | `colab_full_run` | `4_models/b1_groupdro_xgb_v1_20260214_122519/results.json` | B1 full run completed (`weight_mode=station_balanced_prior`, `selection_mode=worst_station_mcc`, selected=`fr_q1`, `q=0.0075`, `pooled_auc=0.6638`). |
| 2026-02-14 | `b1_smoke_20260214_200839` | `local_smoke` | `4_models/b1_smoke_20260214_200839/results.json` | B1 route smoke passed (`weight_mode=station_balanced_prior`, `selection_mode=worst_station_mcc`, `label_mode=official`, `skip_save_model=True`). |
| 2026-02-14 | `11_Colab_ModelGap_B1_v1` | `notebook_added` | `2_notebooks/11_Colab_ModelGap_B1_v1.ipynb` | One-click Colab entry for B1 (station-robust weighting + worst-station selection). |
| 2026-02-14 | `a2r137_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/a2r137_q00001_v1.zip` | Codabench: `auc=0.638121`, `acc=0.886711`, `f1=0.939954`, `mcc=-0.001282`; below baseline (`0.939961`), so A2 marked eliminated. |
| 2026-02-14 | `a2r137_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/a2r137_q00020_v1.zip` | Packed A2 short-name ZIPs from `a2_balanced_xgb_v1_20260214_113741` (`base/q00001/q00002/q00005/q00010/q00020`), local smoke passed. |
| 2026-02-14 | `a2_balanced_xgb_v1_20260214_113741` | `colab_full_run` | `4_models/a2_balanced_xgb_v1_20260214_113741/results.json` | A2 full run completed (`weight_mode=balanced_prior`, `target_pos_rate=0.886724`, `selected=fr_q3`, `n_days=3`, `pooled_auc=0.6566`). |
| 2026-02-14 | `a2_smoke_20260214_193015` | `local_smoke` | `4_models/a2_smoke_20260214_193015/results.json` | A2 weighted route smoke passed (`weight_mode=balanced_prior`, `target_pos_rate=0.886724`, `label_mode=official`, `skip_save_model=True`). |
| 2026-02-14 | `10_Colab_ModelGap_A2_v1` | `notebook_added` | `2_notebooks/10_Colab_ModelGap_A2_v1.ipynb` | One-click Colab entry for A2 (balanced-prior weighting + official labels + configurable run tag). |
| 2026-02-14 | `a1r754_q00005_eval_v1` | `online_eval` | `5_outputs/submissions/a1r754_q00005_v1.zip` | Codabench: `auc=0.627738`, `acc=0.886711`, `f1=0.939953`, `mcc=0.004313`; below baseline (`0.939961`), so current A1 best remains `q00001`. |
| 2026-02-14 | `a1r754_q00001_eval_v1` | `online_eval` | `5_outputs/submissions/a1r754_q00001_v1.zip` | Codabench: `auc=0.627738`, `acc=0.886736`, `f1=0.939968`, `mcc=0.010035`; first A1 online result beats all-ones-equivalent baseline (`0.939961`). |
| 2026-02-14 | `a1r754_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/a1r754_q00020_v1.zip` | Packed A1 short-name ZIPs from `f1push_ranker_v1_20260214_075444` (`base/q00001/q00002/q00005/q00010/q00020`) for Codabench upload. |
| 2026-02-14 | `f1push_ranker_v1_20260214_075444` | `colab_full_run` | `4_models/f1push_ranker_v1_20260214_075444/results.json` | A1 official-label full run completed (`selected=fr_f6`, `n_days=2`, `q=0.01`, `pooled_auc=0.6672`). |
| 2026-02-14 | `09_Colab_ModelGap_A1_v1` | `notebook_added` | `2_notebooks/09_Colab_ModelGap_A1_v1.ipynb` | New one-click Colab entry for model-gap `A1` run (`label_mode=official`, default `full`). |
| 2026-02-14 | `model_gap_v2_kickoff` | `strategy_reset` | `0_README/Model_Gap_Execution_Tracker_v2.md` | Switched from probe-only loops to finite model-gap validation queue (`A1->A2->A3->B1...`) with elimination gates and stop criteria. |
| 2026-02-14 | `consensusai_question_pack_v1` | `literature_intake` | `0_README/ConsensusAI_Literature_Questions_v1.md` | Prepared 8 structured ConsensusAI questions covering prior-shift, robust objectives, GroupDRO, PU learning, calibration, backbone alternatives, and OOD evaluation design. |
| 2026-02-14 | `f1r044_station_probes_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/f1r044s_fernan_q00080_v1.zip` | Stopped per-row probing and switched to station-targeted batch probes (`Fernandina/Lewes/The_Battery`, each ~21 forced negatives) for faster finite search. |
| 2026-02-14 | `f1r044_singleflip_probes_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/f1r044k1_r0001_v1.zip` | Built rank-offset single-flip probes (`r=1..6`), each flips exactly 1 sample (`below_05=1`) to search for a TN without increasing FN. |
| 2026-02-14 | `f1r044_ultra_small_v1` | `online_eval` | `5_outputs/submissions/f1r044u_q00001_v1.zip` | Codabench: `auc=0.6488`, `f1=0.939954`, `mcc=-0.00128`; still below all-ones equivalent (`0.939961`). |
| 2026-02-14 | `f1r044_q00050_eval_v1` | `online_eval` | `5_outputs/submissions/f1r044_q00050_v1.zip` | Codabench: `auc=0.6488`, `f1=0.939700`, `mcc=-0.00607`; flipping lowest 0.05% hurts F1 (FN introduced). |
| 2026-02-14 | `negmine_v1_20260214_111927` | `local_quick_diagnostic` | `4_models/negmine_v1_20260214_111927/results.json` | Diagnostic run with `label_mode=official` completed. CV dropped sharply (`mean_f1≈0.063`, `mean_mcc≈0.037`), confirming strong label-definition shift impact vs prior dynamic route. |
| 2026-02-14 | `f1r113_submission_pack_v1` | `submission_pack` | `5_outputs/submissions/f1r113_q00100_v1.zip` | New F1-push ranker short-name ZIPs generated (`base/q00050/q00100/q00200`); local official ingestion smoke passed (`n=77739`, `num_below_05=77`). |
| 2026-02-14 | `f1push_ranker_v1_20260214_113111` | `local_quick_run` | `4_models/f1push_ranker_v1_20260214_113111/results.json` | New model line: `train_f1push_ranker_v1.py` (label=`union`), selected `fr_q3` + `q=0.002` (`gain=389.0`, pooled AUC `0.7910`). |
| 2026-02-14 | `08_Colab_F1Push_Ranker_v1` | `notebook_added` | `2_notebooks/08_Colab_F1Push_Ranker_v1.ipynb` | One-click Colab notebook for new F1-push ranker route; outputs standardized to `4_models/f1push_ranker_v1_*`. |
| 2026-02-14 | `nm37_final_pick` | `submit_decision` | `5_outputs/submissions/nm37_base_v1.zip` | `q00001/q00002` both slightly below base (`f1=0.939954 < 0.939961`), so final F1-first pick stays at `nm37_base_v1`. |
| 2026-02-14 | `nm37_ultra_small_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/nm37_q00001_v1.zip` | Added ultra-small rank-selective variants (`q=0.00001/0.00002/0.00003/0.00004`) after `nm37_q00005_v1` slightly reduced F1. |
| 2026-02-14 | `negmine_v1_20260214_024057_bias037_eval_v1` | `online_eval` | `5_outputs/submissions/negmine_v1_20260214_024057_bias037_v1.zip` | Online score matched all-ones baseline (`auc=0.6125`, `f1=0.939961`, `mcc=0.0`). |
| 2026-02-14 | `negmine_v1_20260214_024057_bias037_ranksel_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/negmine_v1_20260214_024057_bias037_ranksel_q0002_v1.zip` | Built final tie-break probes on top of `bias037` (`q=0.0002/0.0005/0.0010`) to try pushing F1 above `0.939961`. |
| 2026-02-14 | `negmine_v1_20260214_024057` | `colab_full_run` | `4_models/negmine_v1_20260214_024057/results.json` | 07 notebook full run completed; selected `nm_q1` (`n_days=3`, `alpha=0.15`, `prob_bias=0.1`). |
| 2026-02-14 | `negmine_v1_20260214_024057_submit_v1` | `submission_pack` | `5_outputs/submissions/negmine_v1_20260214_024057_submit_v1.zip` | Added inference wrapper for `negative_mining_pair_v1` bundle, local ingestion smoke passed (`n=77739`, coverage=100%). |
| 2026-02-14 | `negmine_v1_20260214_024057_bias_sweep_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/negmine_v1_20260214_024057_bias020_v1.zip` | Built bias-only variants (`+0.12/+0.15/+0.20/+0.25/+0.30/+0.37`) to tune F1-first recall without retraining. |
| 2026-02-14 | `negmine_v1_20260214_103534` | `local_smoke` | `4_models/negmine_v1_20260214_103534/results.json` | New retraining route smoke-tested with `train_negative_mining_suite.py` (`quick`, `max_train_samples=5000`, `skip_save_model=True`), selected `nm_q1`. |
| 2026-02-14 | `07_Colab_NegativeMining_v1` | `notebook_added` | `2_notebooks/07_Colab_NegativeMining_v1.ipynb` | One-click Colab flow for negative-mining retrain route; output standardized to `4_models/negmine_v1_*`. |
| 2026-02-14 | `future_rank_f1push_eval_v1` | `online_eval` | `5_outputs/submissions/future_rank_f1push_mx_q0050_v1.zip` | Online scores did not beat baseline: best `f1=0.93930` (`mx_q0050`), below `bias027/all-ones` (`0.939961`). |
| 2026-02-14 | `future_rank_f1push_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/future_rank_f1push_mx_q0067_v1.zip` | Third route to beat 0.9433: rank by per-sample future-14d max water from `test_hourly`, force lowest quantile negatives (`q=0.005/0.0067/0.01` + z-score variant). |
| 2026-02-14 | `xgbv1_f1push_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/xgbv1_f1push_q0005_v1.zip` | New push-to-0.9433 route: use `xgboost_v1` ranking with all-ones bias (`+0.47`) and quantile selective negatives (`q=0.005/0.01/0.02/0.03`). |
| 2026-02-14 | `xgb_day2_last3d_t03_final_pick` | `submit_decision` | `5_outputs/submissions/xgb_day2_last3d_t03_bias027_v1.zip` | Final pick for F1-first: `bias027` reached `f1=0.939961`, while rank-selective probes all degraded F1/MCC. |
| 2026-02-14 | `xgb_day2_last3d_t03_ranksel_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/xgb_day2_last3d_t03_ranksel_q0002_v1.zip` | Built tie-break probes from `bias027` using lowest-quantile forced negatives (`q=0.0002/0.0005/0.0010`). |
| 2026-02-14 | `xgb_day2_last3d_t03_bias_high_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/xgb_day2_last3d_t03_bias027_v1.zip` | Added high-bias variants (`+0.10/+0.15/+0.20/+0.27`) after online results showed monotonic F1 gain (`0.8911 -> 0.9073`). |
| 2026-02-14 | `xgb_day2_last3d_t03_bias_sweep_v1` | `no_retrain_submit_sweep` | `5_outputs/submissions/xgb_day2_last3d_t03_bias003_v1.zip` | Generated 3 bias-only packages (`+0.03/+0.05/+0.08`) from same model for F1-first online validation. |
| 2026-02-14 | `xgb_day2_last3d_t03_v2` | `submission_smoke+pack` | `5_outputs/submissions/xgb_day2_last3d_t03_v2.zip` | Source model=`4_models/h100_day2_20260213_155518`; local ingestion passed (`predictions.csv` 77,739 rows). |
| 2026-02-13 | `h100_day2_20260213_155518` | `train_only` | `4_models/h100_day2_20260213_155518/model.pkl` | Fast finalize completed. Selected config: `last_3_days` + `thresh_0.3`; `training_samples=233217`. |
| 2026-02-13 | `h100_day2_20260213_075249` | `quick` | `4_models/h100_day2_20260213_075249/results.json` | Completed. EXP-A best=`last_3_days` (mean MCC=0.3544). EXP-B best threshold=`0.3` (MCC=0.3383). |
| 2026-02-13 | (pending first run) | `quick` | `4_models/h100_day2_<timestamp>/results.json` | Start from quick mode, then decide whether to run full mode. |

## Rule
After each training run:
1. Save/keep the run folder under `4_models/h100_day2_<timestamp>/`.
2. Append one short entry in this file.
3. Add one line in `0_README/Daily_Progress.md`.
